{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import inspect, create_engine\n",
    "import config\n",
    "host = config.host()\n",
    "port = config.port()\n",
    "database = config.database()\n",
    "user = config.user()\n",
    "password = config.password()\n",
    "engine = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database}\")\n",
    "conn = engine.connect()\n",
    "inspector = inspect(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['resources/json_datasets/LCA_Disclosure_Data.json',\n",
       " 'resources/json_datasets/GSEARCH.json',\n",
       " 'resources/json_datasets/H_1B_Disclosure_Data.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "jsonList= []\n",
    "df_dict = {}\n",
    "new_df = pd.DataFrame()\n",
    "for table_name in inspector.get_table_names():\n",
    "    data = pd.read_sql(f\"SELECT * FROM \\\"{table_name}\\\"\", conn)\n",
    "    fn = f'resources/json_datasets/{table_name}.json'\n",
    "    data.to_json(fn)\n",
    "    jsonList.append(fn)\n",
    "    # print(data)\n",
    "    df_dict[table_name] = data\n",
    "    # new_df = pd.concat([new_df,data])\n",
    "\n",
    "\n",
    "conn.close()\n",
    "\n",
    "jsonList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LCA_Disclosure_Data', 'GSEARCH', 'H_1B_Disclosure_Data'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CASE_NUMBER</th>\n",
       "      <th>RECEIVED_DATE</th>\n",
       "      <th>DECISION_DATE</th>\n",
       "      <th>SOC_TITLE</th>\n",
       "      <th>FULL_TIME_POSITION</th>\n",
       "      <th>BEGIN_DATE</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>EMPLOYER_NAME</th>\n",
       "      <th>EMPLOYER_CITY</th>\n",
       "      <th>EMPLOYER_STATE</th>\n",
       "      <th>EMPLOYER_POSTAL_CODE</th>\n",
       "      <th>WAGE_RATE_OF_PAY_FROM</th>\n",
       "      <th>WAGE_UNIT_OF_PAY</th>\n",
       "      <th>PREVAILING_WAGE</th>\n",
       "      <th>PW_UNIT_OF_PAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I-200-19268-495825</td>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>OPERATIONS RESEARCH ANALYSTS</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>BIZINTEX, INC.</td>\n",
       "      <td>WOODSTOCK</td>\n",
       "      <td>GA</td>\n",
       "      <td>30188</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>Year</td>\n",
       "      <td>72280.0</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I-200-19268-874666</td>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>COMPUTER OCCUPATIONS, ALL OTHER</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019-10-10</td>\n",
       "      <td>2022-10-09</td>\n",
       "      <td>LOGIC PLANET, INC.</td>\n",
       "      <td>PRINCETON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>8540</td>\n",
       "      <td>78915.0</td>\n",
       "      <td>Year</td>\n",
       "      <td>76419.0</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I-200-19268-206230</td>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>COMPUTER SYSTEMS ANALYSTS</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019-10-02</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>POLARIS CONSULTING &amp; SERVICES LTD</td>\n",
       "      <td>PISCATAWAY</td>\n",
       "      <td>NJ</td>\n",
       "      <td>08854-6144</td>\n",
       "      <td>87000.0</td>\n",
       "      <td>Year</td>\n",
       "      <td>81890.0</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I-200-19268-379595</td>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>SOFTWARE DEVELOPERS, APPLICATIONS</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>2022-09-24</td>\n",
       "      <td>XENONINFOTEK, INC.</td>\n",
       "      <td>EDISON</td>\n",
       "      <td>NJ</td>\n",
       "      <td>8817</td>\n",
       "      <td>81931.0</td>\n",
       "      <td>Year</td>\n",
       "      <td>81931.0</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I-200-19268-717286</td>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>MANAGEMENT ANALYSTS</td>\n",
       "      <td>Y</td>\n",
       "      <td>2019-10-07</td>\n",
       "      <td>2022-10-06</td>\n",
       "      <td>BIZINTEX, INC.</td>\n",
       "      <td>WOODSTOCK</td>\n",
       "      <td>GA</td>\n",
       "      <td>30188</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>Year</td>\n",
       "      <td>98010.0</td>\n",
       "      <td>Year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CASE_NUMBER RECEIVED_DATE DECISION_DATE  \\\n",
       "0  I-200-19268-495825    2019-09-25    2019-10-01   \n",
       "1  I-200-19268-874666    2019-09-25    2019-10-01   \n",
       "2  I-200-19268-206230    2019-09-25    2019-10-01   \n",
       "3  I-200-19268-379595    2019-09-25    2019-10-01   \n",
       "4  I-200-19268-717286    2019-09-25    2019-10-01   \n",
       "\n",
       "                           SOC_TITLE FULL_TIME_POSITION BEGIN_DATE   END_DATE  \\\n",
       "0       OPERATIONS RESEARCH ANALYSTS                  Y 2019-10-07 2022-10-06   \n",
       "1    COMPUTER OCCUPATIONS, ALL OTHER                  Y 2019-10-10 2022-10-09   \n",
       "2          COMPUTER SYSTEMS ANALYSTS                  Y 2019-10-02 2022-09-01   \n",
       "3  SOFTWARE DEVELOPERS, APPLICATIONS                  Y 2019-09-25 2022-09-24   \n",
       "4                MANAGEMENT ANALYSTS                  Y 2019-10-07 2022-10-06   \n",
       "\n",
       "                       EMPLOYER_NAME EMPLOYER_CITY EMPLOYER_STATE  \\\n",
       "0                     BIZINTEX, INC.     WOODSTOCK             GA   \n",
       "1                 LOGIC PLANET, INC.     PRINCETON             NJ   \n",
       "2  POLARIS CONSULTING & SERVICES LTD    PISCATAWAY             NJ   \n",
       "3                 XENONINFOTEK, INC.        EDISON             NJ   \n",
       "4                     BIZINTEX, INC.     WOODSTOCK             GA   \n",
       "\n",
       "  EMPLOYER_POSTAL_CODE  WAGE_RATE_OF_PAY_FROM WAGE_UNIT_OF_PAY  \\\n",
       "0                30188                73000.0             Year   \n",
       "1                 8540                78915.0             Year   \n",
       "2           08854-6144                87000.0             Year   \n",
       "3                 8817                81931.0             Year   \n",
       "4                30188                99000.0             Year   \n",
       "\n",
       "   PREVAILING_WAGE PW_UNIT_OF_PAY  \n",
       "0          72280.0           Year  \n",
       "1          76419.0           Year  \n",
       "2          81890.0           Year  \n",
       "3          81931.0           Year  \n",
       "4          98010.0           Year  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## concatenate lca and h1b\n",
    "new_df = pd.DataFrame()\n",
    "for f in ['LCA_Disclosure_Data', 'H_1B_Disclosure_Data']:\n",
    "    new_df = pd.concat([new_df,df_dict[f]])\n",
    "new_df = new_df.mask(new_df.eq('None')).dropna()\n",
    "new_df.reset_index(inplace=True,drop=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalPW = []\n",
    "totalWF = []\n",
    "for j,i in new_df.iterrows():\n",
    "    if i['WAGE_UNIT_OF_PAY'] != i['PW_UNIT_OF_PAY']:\n",
    "\n",
    "        ### check for incorrect wage pay using difference\n",
    "        if not abs((i['WAGE_RATE_OF_PAY_FROM']-i['PREVAILING_WAGE'])/(i['WAGE_RATE_OF_PAY_FROM']+i['PREVAILING_WAGE'])) > 0.5:\n",
    "            \n",
    "            avgWage = (i['WAGE_RATE_OF_PAY_FROM']+i['PREVAILING_WAGE'])/2\n",
    "            unitWage = [i['WAGE_UNIT_OF_PAY'],i['PW_UNIT_OF_PAY']]\n",
    "            ### Change to longest pay period (this is based on observed pattern of error)\n",
    "            if 'Year' in unitWage:\n",
    "                unit = 'Year'\n",
    "            elif 'Month' in unitWage:\n",
    "                unit = 'Month'\n",
    "            elif 'Bi-Weekly' in unitWage:\n",
    "                unit = 'Bi-Weekly'\n",
    "            elif 'Week' in unitWage:\n",
    "                unit = 'Week'\n",
    "            elif 'Hour' in unitWage:\n",
    "                unit = 'Hour'\n",
    "            else:\n",
    "                print(unitWage)\n",
    "            i['WAGE_UNIT_OF_PAY'] = unit\n",
    "            i['PW_UNIT_OF_PAY'] = unit\n",
    "\n",
    "    if i['WAGE_UNIT_OF_PAY'] == 'Year':\n",
    "        totalWF.append(i['WAGE_RATE_OF_PAY_FROM'])\n",
    "    elif i['WAGE_UNIT_OF_PAY'] == 'Month':\n",
    "        totalWF.append(i['WAGE_RATE_OF_PAY_FROM'] * 12)\n",
    "    elif i['WAGE_UNIT_OF_PAY'] == 'Week':\n",
    "        totalWF.append(i['WAGE_RATE_OF_PAY_FROM'] * 52)\n",
    "    elif i['WAGE_UNIT_OF_PAY'] == 'Hour':\n",
    "        totalWF.append(i['WAGE_RATE_OF_PAY_FROM'] * 40 * 52)\n",
    "    elif i['WAGE_UNIT_OF_PAY'] == 'Bi-Weekly':\n",
    "        totalWF.append(i['WAGE_RATE_OF_PAY_FROM'] * 26)\n",
    "        \n",
    "    if i['PW_UNIT_OF_PAY'] == 'Year':\n",
    "        totalPW.append(i['PREVAILING_WAGE'])\n",
    "    elif i['PW_UNIT_OF_PAY'] == 'Month':\n",
    "        totalPW.append(i['PREVAILING_WAGE'] * 12)\n",
    "    elif i['PW_UNIT_OF_PAY'] == 'Week':\n",
    "        totalPW.append(i['PREVAILING_WAGE'] * 52)\n",
    "    elif i['PW_UNIT_OF_PAY'] == 'Hour':\n",
    "        totalPW.append(i['PREVAILING_WAGE'] * 40 * 52)\n",
    "    elif i['PW_UNIT_OF_PAY'] == 'Bi-Weekly':\n",
    "        totalPW.append(i['PREVAILING_WAGE'] * 26)\n",
    "new_df['WAGE_RATE_OF_PAY_CALCULATED'] = totalWF\n",
    "new_df['PREVAILING_WAGE_CALCULATED'] = totalPW\n",
    "fixedTitles = [title.upper() for title in new_df['SOC_TITLE']]\n",
    "new_df['SOC_TITLE'] = fixedTitles\n",
    "\n",
    "locs = pd.read_csv('../resources/datasets/stateLoc.csv').set_index('state')\n",
    "\n",
    "wage_mean_df = new_df.groupby(by='EMPLOYER_STATE').median()\n",
    "listingCnt = new_df.groupby(by='EMPLOYER_STATE').count()\n",
    "wageDf = pd.DataFrame(wage_mean_df[['WAGE_RATE_OF_PAY_CALCULATED', 'PREVAILING_WAGE_CALCULATED']])\n",
    "wageDf['LISTING_CNT'] = listingCnt['CASE_NUMBER']\n",
    "wageDf = locs.join(wageDf,how='outer').dropna()\n",
    "wageDf.reset_index(inplace=True)\n",
    "wageDf.rename(columns={'index':'STATE_ABBR'},inplace=True)\n",
    "locs.reset_index(inplace=True)\n",
    "locs.rename(columns={'index':'STATE_ABBR'},inplace=True)\n",
    "constrainDf = new_df[['SOC_TITLE','EMPLOYER_NAME','EMPLOYER_CITY','EMPLOYER_STATE','PREVAILING_WAGE_CALCULATED','WAGE_RATE_OF_PAY_CALCULATED']]\n",
    "\n",
    "gsearch = df_dict['GSEARCH']\n",
    "skills = []\n",
    "for i in gsearch['DESCRIPTION_TOKEN']:\n",
    "    try:\n",
    "        skills.append(i.split('/ '))\n",
    "    except AttributeError:\n",
    "        skills.append([])\n",
    "gsearch['SKILLS'] = skills\n",
    "\n",
    "platform = []\n",
    "for i in gsearch['VIA']:\n",
    "    try:\n",
    "        platform.append(' '.join(i.split(' ')[1:]))\n",
    "    except AttributeError:\n",
    "        platform.append('')\n",
    "\n",
    "gsearch['PLATFORM'] = platform\n",
    "gsearch = gsearch[['TITLE', 'COMPANY_NAME', 'SKILLS',\t'PLATFORM']]\n",
    "gsearch = gsearch.mask(gsearch.eq('')).dropna()\n",
    "searchCnt = pd.DataFrame(gsearch.groupby('PLATFORM').count()['TITLE'].sort_values(ascending = False))\n",
    "valid = [i[0] for i in searchCnt.iterrows() if i[1][0] > 50]\n",
    "gsearch = gsearch[gsearch['PLATFORM'].isin(valid)]\n",
    "searchCnt.rename(columns={'TITLE':'COUNT'},inplace = True)\n",
    "gsearch = pd.merge(gsearch,searchCnt,left_on='PLATFORM',right_index=True).sort_values(by='COUNT',ascending=False).reset_index(drop=True)\n",
    "# # new_df is cleaned and concatenated h1b and lca\n",
    "# # wagedf is infomration concerning wage by state with longitude and latitude\n",
    "# # locs is coordinate of each state\n",
    "# # constrainDF is usable information in a smaller file\n",
    "# # gsearch is cleaned google search data\n",
    "\n",
    "new_df.to_json('resources/json_datasets/LCA_H1b_Combined.json',orient='records')\n",
    "wageDf.to_json('resources/json_datasets/wageInfo.json',orient='records')\n",
    "locs.to_json('resources/json_datasets/locations.json',orient='records')\n",
    "constrainDf.to_json('resources/json_datasets/jobTitle.json',orient='records')\n",
    "gsearch.to_json('resources/json_datasets/gsearch.json',orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaryDf = pd.read_csv('../resources/datasets/Data Science Salary 2021 to 2023.csv')\n",
    "salaryDf = salaryDf[salaryDf['company_location'] == 'US']\n",
    "cat = []\n",
    "for i in salaryDf['job_title']:\n",
    "    found = False\n",
    "    if 'Engineer' in i or 'Architect' in i:\n",
    "\n",
    "        found = True\n",
    "        cat.append('Engineer/Architect')\n",
    "\n",
    "    elif 'Scientist' in i or 'Science' in i or 'Analyst' in i or 'Analytics' in i:\n",
    "\n",
    "        found = True\n",
    "        cat.append('Science/Analyst')\n",
    "    elif 'Analyst' in i or 'Analytics' in i:\n",
    "\n",
    "        found = True\n",
    "\n",
    "    elif not found:\n",
    "\n",
    "        cat.append('Other')\n",
    "salaryDf['category'] = cat\n",
    "salaryDf.groupby(['category','experience_level']).median()['salary'].to_json('resources/json_datasets/test.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
